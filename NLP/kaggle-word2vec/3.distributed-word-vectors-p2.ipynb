{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model that we created in Part 2\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"models\\\\300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labelled train reviews, 25000 labelled test reviews, and 50000 unlabelled reviews\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read training data\n",
    "train = pd.read_csv(\"data\\\\labeledTrainData.tsv\", header=0, \n",
    "    delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "test = pd.read_csv(\"data\\\\testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabelled_train = pd.read_csv(\"data\\\\unlabeledTrainData.tsv\", header=0, \n",
    "    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print(\"Read %d labelled train reviews, %d labelled test reviews, \" \\\n",
    " \"and %d unlabelled reviews\\n\" % (train[\"review\"].size,  \\\n",
    " test[\"review\"].size, unlabelled_train[\"review\"].size ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16490, 300)\n[ -6.33130446e-02  -9.51148346e-02  -1.13297123e-02   2.06500944e-02\n   7.69971497e-03   3.90268639e-02  -2.31053215e-03   5.74429892e-02\n  -7.89635256e-02  -8.16961229e-02  -4.67109419e-02  -2.64932867e-02\n  -3.51126157e-02   2.89048813e-02   4.62030284e-02  -3.96941677e-02\n   7.13620633e-02   1.02953045e-02   5.50104231e-02   8.82932693e-02\n  -5.12857474e-02  -6.33965358e-02   9.97599661e-02  -8.15247477e-04\n   1.72204655e-02   6.61159446e-03   5.32784984e-02   4.57147136e-02\n  -6.43707365e-02   7.38542452e-02   6.92851003e-03  -7.33929053e-02\n   5.16038295e-03   7.72529915e-02  -2.53960341e-02   4.63377638e-03\n   8.82617850e-03  -3.54095275e-04   8.12259167e-02  -6.88227639e-02\n  -4.25982922e-02   2.36869045e-02  -3.61694470e-02  -1.70206651e-02\n   1.36775151e-02  -9.27254185e-02   2.43001468e-02  -7.25661069e-02\n   1.55967183e-03   2.96756774e-02   6.78326264e-02  -1.84335455e-01\n  -1.54907286e-01  -8.04380104e-02   5.98481931e-02  -9.95170400e-02\n  -9.91423801e-02  -4.38057035e-02  -3.80052030e-02   2.80800425e-02\n  -1.08000357e-02  -2.74348859e-04   2.33396832e-02  -3.48251089e-02\n  -3.07612345e-02   2.77959742e-02  -1.54216409e-01   2.74511371e-02\n  -6.09358922e-02   5.48205264e-02   9.23384279e-02  -2.19384376e-02\n  -2.37434786e-02  -8.65105316e-02  -6.12856634e-02   9.50344130e-02\n  -4.02965397e-02   3.83593887e-02  -2.50642821e-02  -8.26234296e-02\n  -4.22664583e-02   5.75609840e-02  -7.67684653e-02   1.13526667e-02\n  -1.58772469e-02   7.14422858e-05   1.02554776e-01  -4.31775525e-02\n   2.20527761e-02  -4.93628420e-02  -1.22021902e-02  -2.34833565e-02\n  -2.74095628e-02  -2.78890431e-02  -2.24988558e-03   1.07226111e-02\n  -6.89179525e-02  -7.86489528e-03   3.30307819e-02   1.64511483e-02\n   6.01336919e-02  -6.33181781e-02  -9.38882828e-02  -2.19664704e-02\n   8.35760310e-02  -2.37592198e-02  -8.90779716e-04  -5.41884527e-02\n   5.86812245e-03  -5.90648465e-02   9.93857905e-02   6.50684163e-02\n  -8.64192694e-02  -2.88192704e-02   2.75472552e-03  -2.23436467e-02\n   4.32903357e-02   7.63649447e-03  -2.09735688e-02   9.90231037e-02\n   3.00155841e-02  -1.69998016e-02   6.84521943e-02  -2.30259858e-02\n   6.52220398e-02   6.74079508e-02  -8.68210773e-05   9.79808420e-02\n   4.88520786e-02   8.00081417e-02   3.70639190e-02  -1.08486312e-02\n  -7.16379359e-02   1.86737068e-02   2.92702541e-02   7.40659190e-03\n  -5.97940274e-02  -6.29218221e-02  -3.12629938e-02  -6.55127615e-02\n  -4.27996479e-02  -6.26253486e-02  -4.99501228e-02  -2.52766050e-02\n   2.94949710e-02   7.11829886e-02  -6.17003404e-02   9.22088698e-02\n   3.24589238e-02   1.73757561e-02   1.68430116e-02   4.36829217e-02\n  -8.65171477e-02   2.72921566e-02   1.49629917e-02   5.94136231e-02\n   2.79254988e-02   2.84835659e-02   7.57136047e-02   1.91946812e-02\n   9.48515162e-02  -3.63531969e-02   2.06080992e-02  -5.86355217e-02\n  -1.39932288e-02   5.81959076e-02   9.64878201e-02  -1.56904664e-02\n   6.93406612e-02   1.55358603e-02  -3.33581083e-02   1.40782949e-02\n   2.35913380e-04   2.09534634e-03  -7.20728282e-03  -8.72382820e-02\n  -2.01076418e-02  -9.28068534e-03   6.27900437e-02   5.56331314e-02\n  -1.58244139e-03   1.29359514e-02  -2.26736721e-02   5.39085642e-02\n  -4.37677354e-02  -7.10329181e-03  -1.43902134e-02  -5.01908036e-03\n  -1.27461568e-01   2.31207954e-03  -7.03628287e-02  -1.03032235e-02\n   1.70358308e-02  -3.89309078e-02  -9.12471861e-02   4.27215211e-02\n   3.23023871e-02   1.03125311e-01  -2.42914073e-02   3.85914668e-02\n   8.76768082e-02   1.08573260e-02   1.29086636e-02   1.13285547e-02\n   3.59113514e-02   6.53433800e-02  -7.22837225e-02   4.18853015e-02\n  -4.71459776e-02   6.37638271e-02   9.72504243e-02  -1.69469267e-02\n  -3.90774384e-02   2.38487236e-02  -7.33492002e-02   4.07288224e-02\n   7.83467144e-02   5.49709192e-03  -4.10722978e-02   1.06770499e-02\n  -1.89625174e-02   1.27352297e-01   5.70847429e-02   2.40432248e-02\n   3.83244525e-03   5.50538525e-02   4.54336032e-02   2.13062135e-03\n  -5.63535094e-02  -3.87030058e-02  -1.30110784e-02   1.43537819e-02\n   6.68921545e-02   1.12707019e-01   7.35103935e-02   8.61930698e-02\n  -2.33646878e-03  -1.01548694e-01  -3.33259217e-02   4.46565561e-02\n  -2.35810690e-02  -3.32587101e-02   3.45482938e-02  -1.08583264e-01\n   1.15456490e-03   1.13511190e-01   1.35482959e-02  -5.39341336e-03\n   1.81431659e-02  -5.53306714e-02  -1.12137459e-01  -6.59750551e-02\n  -2.93264631e-02  -5.73076308e-02   2.99130883e-02   8.58173764e-04\n   1.05065122e-01  -3.17467526e-02  -9.68470126e-02   1.48871318e-02\n   3.26384194e-02  -1.20766079e-02  -2.03746967e-02  -4.79157344e-02\n  -1.34229688e-02  -6.80219680e-02  -3.53346989e-02   4.62680534e-02\n  -3.82098854e-02  -1.14864662e-01  -4.50599641e-02   2.38955580e-02\n  -4.28839177e-02  -5.16580679e-02  -5.94546385e-02   2.25392990e-02\n  -4.35100822e-03   1.86853819e-02   2.55989283e-02  -7.68615119e-03\n   5.85935824e-02   3.87294926e-02  -1.02415378e-03  -1.02815509e-01\n  -5.08720875e-02  -5.45430090e-03   2.47697905e-01   1.05825283e-01\n  -4.11999598e-02  -2.80185957e-02  -8.89015496e-02   6.49864599e-02\n   8.92801434e-02   9.66773257e-02  -2.57427269e-03  -3.67863737e-02\n  -9.05254707e-02   5.19117899e-02   9.05299261e-02   7.43961856e-02]\n"
     ]
    }
   ],
   "source": [
    "# syn0 property contains the feature vectors.\n",
    "# We've got about 17k words overall with 300 features to describe each one.\n",
    "print(model.syn0.shape)\n",
    "print(model['flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n 'and',\n 'a',\n 'of',\n 'to',\n 'is',\n 'it',\n 'in',\n 'i',\n 'this',\n 'that',\n 's',\n 'was',\n 'as',\n 'with',\n 'for',\n 'movie',\n 'but',\n 'film',\n 'you',\n 't',\n 'on',\n 'not',\n 'he',\n 'are',\n 'his',\n 'have',\n 'be',\n 'one',\n 'all',\n 'at',\n 'they',\n 'by',\n 'who',\n 'an',\n 'from',\n 'so',\n 'like',\n 'there',\n 'her',\n 'or',\n 'just',\n 'about',\n 'out',\n 'has',\n 'if',\n 'what',\n 'some',\n 'good',\n 'can',\n 'more',\n 'when',\n 'very',\n 'she',\n 'up',\n 'no',\n 'time',\n 'even',\n 'would',\n 'my',\n 'which',\n 'their',\n 'story',\n 'only',\n 'really',\n 'see',\n 'had',\n 'were',\n 'well',\n 'we',\n 'me',\n 'than',\n 'much',\n 'bad',\n 'get',\n 'been',\n 'people',\n 'also',\n 'into',\n 'do',\n 'great',\n 'other',\n 'will',\n 'first',\n 'because',\n 'him',\n 'how',\n 'most',\n 'don',\n 'them',\n 'made',\n 'its',\n 'make',\n 'then',\n 'way',\n 'could',\n 'too',\n 'movies',\n 'after',\n 'any',\n 'characters',\n 'character',\n 'think',\n 'films',\n 'two',\n 'watch',\n 'being',\n 'many',\n 'plot',\n 'seen',\n 'never',\n 'where',\n 'love',\n 'life',\n 'little',\n 'acting',\n 'best',\n 'did',\n 'over',\n 'off',\n 'know',\n 'show',\n 'ever',\n 'does',\n 'man',\n 'better',\n 'your',\n 'here',\n 'end',\n 'scene',\n 'these',\n 'still',\n 'while',\n 'why',\n 'scenes',\n 'say',\n 'something',\n 'go',\n 've',\n 'm',\n 'should',\n 'such',\n 'back',\n 'through',\n 'real',\n 'those',\n 'now',\n 're',\n 'watching',\n 'doesn',\n 'thing',\n 'though',\n 'director',\n 'years',\n 'actors',\n 'funny',\n 'old',\n 'didn',\n 'another',\n 'new',\n 'nothing',\n 'makes',\n 'work',\n 'actually',\n 'going',\n 'before',\n 'look',\n 'find',\n 'same',\n 'lot',\n 'few',\n 'part',\n 'every',\n 'again',\n 'world',\n 'cast',\n 'us',\n 'things',\n 'horror',\n 'quite',\n 'want',\n 'action',\n 'down',\n 'pretty',\n 'young',\n 'around',\n 'seems',\n 'fact',\n 'take',\n 'however',\n 'enough',\n 'got',\n 'long',\n 'both',\n 'thought',\n 'big',\n 'own',\n 'give',\n 'between',\n 'd',\n 'comedy',\n 'series',\n 'must',\n 'may',\n 'right',\n 'original',\n 'without',\n 'role',\n 'interesting',\n 'come',\n 'times',\n 'always',\n 'isn',\n 'guy',\n 'saw',\n 'whole',\n 'gets',\n 'least',\n 'point',\n 'almost',\n 'bit',\n 'script',\n 'music',\n 'done',\n 'last',\n 'minutes',\n 'far',\n 'family',\n 'feel',\n 'since',\n 'making',\n 'll',\n 'girl',\n 'might',\n 'performance',\n 'anything',\n 'yet',\n 'away',\n 'probably',\n 'am',\n 'woman',\n 'tv',\n 'kind',\n 'hard',\n 'fun',\n 'rather',\n 'day',\n 'worst',\n 'sure',\n 'played',\n 'anyone',\n 'each',\n 'found',\n 'especially',\n 'having',\n 'our',\n 'trying',\n 'screen',\n 'looking',\n 'believe',\n 'different',\n 'although',\n 'place',\n 'course',\n 'goes',\n 'sense',\n 'set',\n 'comes',\n 'ending',\n 'maybe',\n 'shows',\n 'worth',\n 'american',\n 'three',\n 'dvd',\n 'money',\n 'put',\n 'looks',\n 'once',\n 'everything',\n 'actor',\n 'someone',\n 'let',\n 'plays',\n 'effects',\n 'main',\n 'john',\n 'wasn',\n 'year',\n 'together',\n 'reason',\n 'book',\n 'true',\n 'everyone',\n 'during',\n 'instead',\n 'takes',\n 'said',\n 'job',\n 'high',\n 'play',\n 'special',\n 'war',\n 'seem',\n 'night',\n 'watched',\n 'later',\n 'audience',\n 'wife',\n 'himself',\n 'star',\n 'black',\n 'half',\n 'seeing',\n 'left',\n 'death',\n 'idea',\n 'excellent',\n 'beautiful',\n 'shot',\n 'house',\n 'second',\n 'father',\n 'simply',\n 'used',\n 'men',\n 'dead',\n 'else',\n 'mind',\n 'version',\n 'less',\n 'completely',\n 'hollywood',\n 'nice',\n 'poor',\n 'fan',\n 'budget',\n 'women',\n 'help',\n 'home',\n 'line',\n 'sex',\n 'boring',\n 'performances',\n 'along',\n 'try',\n 'top',\n 'either',\n 'short',\n 'read',\n 'low',\n 'wrong',\n 'use',\n 'until',\n 'friends',\n 'camera',\n 'kids',\n 'given',\n 'couple',\n 'next',\n 'need',\n 'start',\n 'enjoy',\n 'full',\n 'classic',\n 'production',\n 'rest',\n 'truly',\n 'perhaps',\n 'stupid',\n 'awful',\n 'school',\n 'moments',\n 'video',\n 'mother',\n 'tell',\n 'mean',\n 'getting',\n 'face',\n 'keep',\n 'came',\n 'won',\n 'understand',\n 'small',\n 'terrible',\n 'others',\n 'recommend',\n 'name',\n 'style',\n 'playing',\n 'itself',\n 'boy',\n 'wonderful',\n 'doing',\n 'stars',\n 'remember',\n 'person',\n 'definitely',\n 'gives',\n 'often',\n 'lost',\n 'dialogue',\n 'written',\n 'live',\n 'early',\n 'lines',\n 'perfect',\n 'human',\n 'case',\n 'entertaining',\n 'head',\n 'yes',\n 'title',\n 'become',\n 'went',\n 'couldn',\n 'hope',\n 'episode',\n 'children',\n 'liked',\n 'friend',\n 'certainly',\n 'based',\n 'supposed',\n 'picture',\n 'piece',\n 'problem',\n 'finally',\n 'absolutely',\n 'against',\n 'oh',\n 'drama',\n 'fans',\n 'sort',\n 'several',\n 'overall',\n 'cinema',\n 'entire',\n 'felt',\n 'under',\n 'son',\n 'worse',\n 'laugh',\n 'called',\n 'evil',\n 'direction',\n 'lives',\n 'waste',\n 'killer',\n 'lead',\n 'humor',\n 'guys',\n 'care',\n 'beginning',\n 'white',\n 'dark',\n 'game',\n 'despite',\n 'seemed',\n 'final',\n 'b',\n 'becomes',\n 'wanted',\n 'unfortunately',\n 'loved',\n 'mr',\n 'throughout',\n 'totally',\n 'history',\n 'already',\n 'genre',\n 'turn',\n 'town',\n 'guess',\n 'fine',\n 'able',\n 'days',\n 'heart',\n 'city',\n 'flick',\n 'act',\n 'run',\n 'side',\n 'wants',\n 'quality',\n 'today',\n 'tries',\n 'child',\n 'hand',\n 'sound',\n 'kill',\n 'close',\n 'horrible',\n 'past',\n 'example',\n 'starts',\n 'writing',\n 'viewer',\n 'turns',\n 'themselves',\n 'amazing',\n 'enjoyed',\n 'etc',\n 'car',\n 'parts',\n 'behind',\n 'directed',\n 'works',\n 'expect',\n 'michael',\n 'killed',\n 'matter',\n 'daughter',\n 'soon',\n 'fight',\n 'favorite',\n 'kid',\n 'self',\n 'decent',\n 'stuff',\n 'gave',\n 'blood',\n 'sometimes',\n 'type',\n 'actress',\n 'eyes',\n 'thinking',\n 'group',\n 'girls',\n 'art',\n 'violence',\n 'obviously',\n 'brilliant',\n 'stop',\n 'stories',\n 'late',\n 'hour',\n 'known',\n 'myself',\n 'except',\n 'writer',\n 'happened',\n 'hero',\n 'says',\n 'god',\n 'feeling',\n 'highly',\n 'coming',\n 'heard',\n 'roles',\n 'extremely',\n 'police',\n 'took',\n 'happens',\n 'leave',\n 'slow',\n 'experience',\n 'moment',\n 'husband',\n 'anyway',\n 'voice',\n 'hell',\n 'wouldn',\n 'murder',\n 'attempt',\n 'involved',\n 'age',\n 'obvious',\n 'living',\n 'interest',\n 'including',\n 'score',\n 'strong',\n 'looked',\n 'taken',\n 'told',\n 'david',\n 'save',\n 'brother',\n 'ok',\n 'wonder',\n 'none',\n 'happen',\n 'cut',\n 'hours',\n 'career',\n 'please',\n 'cool',\n 'robert',\n 'chance',\n 'particularly',\n 'gore',\n 'james',\n 'cannot',\n 'simple',\n 'hit',\n 'across',\n 'ago',\n 'complete',\n 'exactly',\n 'lack',\n 'hilarious',\n 'crap',\n 'o',\n 'annoying',\n 'possible',\n 'alone',\n 'power',\n 'relationship',\n 'light',\n 'serious',\n 'sad',\n 'important',\n 'level',\n 'running',\n 'documentary',\n 'seriously',\n 'usually',\n 'whose',\n 'female',\n 'reality',\n 'ends',\n 'scary',\n 'order',\n 'somewhat',\n 'talent',\n 'happy',\n 'finds',\n 'taking',\n 'song',\n 'middle',\n 'number',\n 'shown',\n 'room',\n 'ridiculous',\n 'strange',\n 'change',\n 'call',\n 'basically',\n 'released',\n 'usual',\n 'body',\n 'opening',\n 'jokes',\n 'turned',\n 'mostly',\n 'english',\n 'country',\n 'wish',\n 'yourself',\n 'apparently',\n 'cinematography',\n 'opinion',\n 'silly',\n 'novel',\n 'attention',\n 'view',\n 'four',\n 'started',\n 'word',\n 'saying',\n 'jack',\n 'disappointed',\n 'miss',\n 'sequel',\n 'single',\n 'talking',\n 'huge',\n 'thriller',\n 'future',\n 'clich',\n 'shots',\n 'words',\n 'major',\n 'cheap',\n 'straight',\n 'non',\n 'clearly',\n 'rating',\n 'modern',\n 'beyond',\n 'knows',\n 'knew',\n 'ones',\n 'due',\n 'fast',\n 'problems',\n 'events',\n 'sets',\n 'british',\n 'king',\n 'talk',\n 'tells',\n 'comic',\n 'french',\n 'parents',\n 'bring',\n 'die',\n 'easily',\n 'aren',\n 'entertainment',\n 'local',\n 'earth',\n 'add',\n 'class',\n 'sequence',\n 'upon',\n 'george',\n 'above',\n 'musical',\n 'television',\n 'within',\n 'giving',\n 'falls',\n 'similar',\n 'york',\n 'storyline',\n 'supporting',\n 'ten',\n 'clear',\n 'mystery',\n 'haven',\n 'easy',\n 'appears',\n 'romantic',\n 'hate',\n 'five',\n 'predictable',\n 'review',\n 'near',\n 'typical',\n 'lots',\n 'ways',\n 'team',\n 'bunch',\n 'enjoyable',\n 'begins',\n 'named',\n 'dialog',\n 'general',\n 'stand',\n 'crime',\n 'working',\n 'elements',\n 'mention',\n 'eye',\n 'message',\n 'e',\n 'theme',\n 'filmed',\n 'richard',\n 'episodes',\n 'points',\n 'avoid',\n 'certain',\n 'songs',\n 'red',\n 'america',\n 'sorry',\n 'tale',\n 'whether',\n 'release',\n 'gay',\n 'dull',\n 'surprised',\n 'moving',\n 'among',\n 'tom',\n 'th',\n 'viewers',\n 'stay',\n 'de',\n 'using',\n 'minute',\n 'fall',\n 'needs',\n 'effort',\n 'feels',\n 'gone',\n 'space',\n 'lee',\n 'leads',\n 'kept',\n 'paul',\n 'nearly',\n 'theater',\n 'tried',\n 'herself',\n 'comments',\n 'means',\n 'peter',\n 'period',\n 'showing',\n 'third',\n 'truth',\n 'sister',\n 'brought',\n 'suspense',\n 'buy',\n 'doubt',\n 'soundtrack',\n 'somehow',\n 'killing',\n 'lady',\n 'feature',\n 'follow',\n 'sequences',\n 'viewing',\n 'fantastic',\n 'editing',\n 'form',\n 'famous',\n 'material',\n 'realistic',\n 'rent',\n 'average',\n 'cop',\n 'okay',\n 'dog',\n 'check',\n 'whatever',\n 'monster',\n 'rock',\n 'reviews',\n 'imagine',\n 'move',\n 'figure',\n 'oscar',\n 'surprise',\n 'forget',\n 'lame',\n 'fi',\n 'believable',\n 'premise',\n 'weak',\n 'animation',\n 'indeed',\n 'deal',\n 'poorly',\n 'sci',\n 'free',\n 'possibly',\n 'actual',\n 'expected',\n 'learn',\n 'hear',\n 'eventually',\n 'dr',\n 'stage',\n 'forced',\n 'sexual',\n 'note',\n 'atmosphere',\n 'deep',\n 'society',\n 'greatest',\n 'sit',\n 'otherwise',\n 'open',\n 'wait',\n 'leaves',\n 'difficult',\n 'question',\n 'romance',\n 'decided',\n 'screenplay',\n 'begin',\n 'reading',\n 'plus',\n 'joe',\n 'situation',\n 'western',\n 'became',\n 'particular',\n 'subject',\n 'earlier',\n 'hot',\n 'nor',\n 'male',\n 'towards',\n 'box',\n 'crew',\n 'gun',\n 'brothers',\n 'interested',\n 'personal',\n 'acted',\n 'street',\n 'meet',\n 'credits',\n 'previous',\n 'cheesy',\n 'imdb',\n 'business',\n 'footage',\n 'powerful',\n 'memorable',\n 'worked',\n 'battle',\n 'shame',\n 'writers',\n 'mess',\n 'effect',\n 'laughs',\n 'season',\n 'features',\n 'whom',\n 'result',\n 'dramatic',\n 'older',\n 'air',\n 'setting',\n 'perfectly',\n 'unless',\n 'era',\n 'quickly',\n 'needed',\n 'keeps',\n 'nature',\n 'hands',\n 'boys',\n 'baby',\n 'crazy',\n 'bill',\n 'total',\n 'badly',\n 'background',\n 'directing',\n 'realize',\n 'emotional',\n 'mark',\n 'forward',\n 'comment',\n 'present',\n 'japanese',\n 'appear',\n 'twist',\n 'development',\n 'girlfriend',\n 'pay',\n 'telling',\n 'write',\n 'superb',\n 'rich',\n 'various',\n 'meets',\n 'c',\n 'unique',\n 'dance',\n 'weird',\n 'island',\n 'william',\n 'directors',\n 'plenty',\n 'break',\n 'secret',\n 'fighting',\n 'disney',\n 'front',\n 'apart',\n 'brings',\n 'sounds',\n 'masterpiece',\n 'doctor',\n 'fairly',\n 'incredibly',\n 'outside',\n 'villain',\n 'dream',\n 'married',\n 'missing',\n 'party',\n 'leading',\n 'manages',\n 'return',\n 'beauty',\n 'remake',\n 'reasons',\n 'inside',\n 'zombie',\n 'fantasy',\n 'list',\n 'admit',\n 'rate',\n 'ideas',\n 'political',\n 'create',\n 'creepy',\n 'ask',\n 'meant',\n 'joke',\n 'unlike',\n 'potential',\n 'cute',\n 'dumb',\n 'success',\n 'copy',\n 'portrayed',\n 'nudity',\n 'fails',\n ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this list contains all the words in the model vocabulary\n",
    "model.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocabulary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n\nThe code that caused this warning is on line 184 of the file C:\\Miniconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n\n BeautifulSoup([your markup])\n\nto this:\n\n BeautifulSoup([your markup], \"html.parser\")\n\n  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\nReview 2000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 3000 of 25000\nReview 4000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 5000 of 25000\nReview 6000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 7000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 8000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 9000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 10000 of 25000\nReview 11000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 12000 of 25000\nReview 13000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 14000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 15000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 16000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 17000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 18000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 19000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 20000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 21000 of 25000\nReview 22000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 23000 of 25000\nReview 24000 of 25000\nCreating average feature vecs for test reviews\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 2000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 3000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 4000 of 25000\nReview 5000 of 25000\nReview 6000 of 25000\nReview 7000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 8000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 9000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 10000 of 25000\nReview 11000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 12000 of 25000\nReview 13000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 14000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 15000 of 25000\nReview 16000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 17000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 18000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 19000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 20000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 21000 of 25000\nReview 22000 of 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 23000 of 25000\nReview 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "num_features = 300\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, \\\n",
    "        remove_stopwords=True))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print(\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, \\\n",
    "        remove_stopwords=True))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100, oob_score=True )\n",
    "\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(trainDataVecs, train[\"sentiment\"])\n",
    "\n",
    "# Test & extract results \n",
    "result = forest.predict(testDataVecs)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv(\"Word2Vec_AverageVectors.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82904\n"
     ]
    }
   ],
   "source": [
    "print(forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  659.7517893314362 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] // 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans(n_clusters = num_clusters)\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nCluster 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fischer']\n\nCluster 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['symbolism', 'literal', 'metaphorical', 'symbolic', 'rooted', 'warped', 'hazy', 'contradiction', 'skewed']\n\nCluster 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beating']\n\nCluster 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kiki']\n\nCluster 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bars', 'rooms', 'beds', 'keys', 'monitors', 'meetings', 'houses', 'traps', 'homes', 'furniture', 'halls', 'apartments', 'boxes', 'buildings']\n\nCluster 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liz']\n\nCluster 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fare', 'comedies', 'movies', 'films', 'slashers', 'thrillers', 'pics', 'flicks', 'dramas']\n\nCluster 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hapless', 'headed', 'nutty', 'witted', 'heavies', 'bumbling', 'misfit']\n\nCluster 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mexicans', 'turks', 'vikings', 'brits', 'russians', 'europeans']\n\nCluster 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coltrane', 'magnum']\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in range(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print(\"\\nCluster %d\" % cluster)\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in range(0,len(word_centroid_map.values())):\n",
    "        if(list(word_centroid_map.values())[i] == cluster ):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(train_centroids,train[\"sentiment\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv(\"BagOfCentroids.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try plain old logistic regression\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "model = LR()\n",
    "lr = model.fit(train_centroids,train[\"sentiment\"])\n",
    "result = model.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv(\"BagOfCentroidsLogisticRegression.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
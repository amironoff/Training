{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Check that we're using the fast C++ word2vec implementation via Cython\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION\n",
    "base_data_path = \"D:\\Projects\\Datasets\"\n",
    "w2vec_path = os.path.join(base_data_path, \"word2vec\\GoogleNews-vectors-negative300.bin.gz\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(w2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents and build a tf-idf matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "document_path = os.path.join(base_data_path, \"products\\strawberry.json\")\n",
    "all_docs = all_docs[all_docs.description.notnull()]\n",
    "all_docs = all_docs[all_docs.id.notnull()]\n",
    "all_docs.reset_index(inplace=True)\n",
    "all_docs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_docs.iloc[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n ('dog', 0.7609457969665527),\n ('kitten', 0.7464984655380249),\n ('feline', 0.7326234579086304),\n ('beagle', 0.7150583267211914)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('cat', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_averaged_sentence_vector(sentence, wv):\n",
    "    v = np.zeros(300)\n",
    "    for w in sentence.split():\n",
    "        if w in wv:\n",
    "            v += wv[w]\n",
    "    return v / len(sentence)\n",
    "\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "title_vectors = all_docs['description'].map(lambda title: generate_averaged_sentence_vector(title, model.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14022197143923812"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = generate_averaged_sentence_vector(\"hello world\", model)\n",
    "vec_b = generate_averaged_sentence_vector(\"dr dr dr\", model)\n",
    "cosine_sim(vec_a, vec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5062, 0.30856972067642469], [593, 0.3080234722885381], [3810, 0.30320928367575523], [7744, 0.30280123690461319], [3811, 0.30251419308402017], [2309, 0.30121252502837897], [592, 0.30096395772790197], [4018, 0.29863675786339677], [4019, 0.29863675786339677], [4192, 0.29001321375288774], [4716, 0.28590449536992468], [5102, 0.28573854408056887], [4146, 0.28303741199266164], [4147, 0.28303741199266164], [1794, 0.2804992274904079], [755, 0.27937647322278569], [5104, 0.27798425700913082], [591, 0.27750658551620799], [2126, 0.27732629027356259], [7850, 0.27714079268746628], [1283, 0.2764406058396488], [590, 0.27603459822677301], [1140, 0.2760248634076326], [4144, 0.27587447932665959], [4732, 0.2745014601663443]]\n[5062, 593, 3810, 7744, 3811, 2309, 592, 4018, 4019, 4192, 4716, 5102, 4146, 4147, 1794, 755, 5104, 591, 2126, 7850, 1283, 590, 1140, 4144, 4732]\n"
     ]
    }
   ],
   "source": [
    "query = \"cat\"\n",
    "\n",
    "\n",
    "def find_top_n_docs(query: str, num_docs, vectors, w2v_model):\n",
    "    query_vector = generate_averaged_sentence_vector(query, w2v_model)\n",
    "    rankings = []\n",
    "    i = 0\n",
    "    for product_vector in vectors:\n",
    "        product_similarity = cosine_sim(query_vector, product_vector)\n",
    "        rankings.append([i, product_similarity])\n",
    "        i += 1\n",
    "        \n",
    "    return_value = sorted(rankings, key=lambda ranking: -ranking[1])\n",
    "    \n",
    "    return return_value[:num_docs]\n",
    "\n",
    "print(find_top_n_docs(query, 25, title_vectors, model))\n",
    "\n",
    "result_idx = list(map(lambda item: item[0], find_top_n_docs(query, 25, title_vectors, model)))\n",
    "print(result_idx)\n",
    "#all_docs.iloc[result_idx][\"title\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
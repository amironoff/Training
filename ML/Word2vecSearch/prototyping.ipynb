{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "# Check that we're using the fast C++ word2vec implementation via Cython\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION\n",
    "base_data_path = \"D:\\Projects\\Datasets\"\n",
    "w2vec_path = os.path.join(base_data_path, \"word2vec\\GoogleNews-vectors-negative300.bin.gz\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(w2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>has_variants</th>\n",
       "      <th>id</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>original_price</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7956.000000</td>\n",
       "      <td>7956.0</td>\n",
       "      <td>7956.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5846.000000</td>\n",
       "      <td>7956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5353.855706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153472.768728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.030790</td>\n",
       "      <td>60.909565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2781.236612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52164.105949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.578493</td>\n",
       "      <td>74.264470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7595.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3205.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127082.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5570.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169148.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7694.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193097.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214224.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>2870.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>has_variants</th>\n",
       "      <th>id</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>original_price</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7956.000000</td>\n",
       "      <td>7956.0</td>\n",
       "      <td>7956.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5846.000000</td>\n",
       "      <td>7956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5353.855706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153472.768728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.030790</td>\n",
       "      <td>60.909565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2781.236612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52164.105949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.578493</td>\n",
       "      <td>74.264470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7595.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3205.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127082.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5570.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169148.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7694.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193097.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214224.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>2870.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the documents and build a tf-idf matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "document_path = os.path.join(base_data_path, \"products\\strawberry.json\")\n",
    "all_docs = pd.read_json(document_path)\n",
    "all_docs = all_docs[all_docs.description.notnull()]\n",
    "all_docs = all_docs[all_docs.id.notnull()]\n",
    "all_docs.reset_index(inplace=True)\n",
    "all_docs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                               1453\nbrand                                                L'Artisan Parfumeur\ncategory                                                         perfume\ndescription                          Drole De Rose Eau De Toilette Spray\nhas_variants                                                           0\nid                                                                127139\nimages                 [{'url': 'https://a.cdnsbn.com/images/products...\nis_deleted                                                           NaN\noriginal_price                                                     136.5\nprice                                                               64.5\nproduct_image_urls     [https://a.cdnsbn.com/images/products/l/127139...\nrequest_fingerprint             bdbffe5c72bc1c34a25f5289b2d2e2a6b999966d\nsize                                                         100ml/3.4oz\ntitle                                Drole De Rose Eau De Toilette Spray\nurl                    https://us.strawberrynet.com/perfume/l-artisan...\nvariants                                                             NaN\nName: 999, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs.iloc[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'sweet_tea' not in vocabulary\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e81d55e09640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sweet_tea'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilar_by_word\u001b[0;34m(self, word, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \"\"\"\n\u001b[1;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilar_by_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'sweet_tea' not in vocabulary\""
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.similar_by_word('sweet_tea', topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sentence_vector_sum(sentence, wv):\n",
    "    v = np.zeros(wv.vector_size)\n",
    "    for w in sentence.split():\n",
    "        if w.lower() in wv:\n",
    "            #print(w.lower())\n",
    "            v += wv[w.lower()]\n",
    "    return v\n",
    "\n",
    "\n",
    "def generate_averaged_sentence_vector(sentence, wv):\n",
    "    v = generate_sentence_vector_sum(sentence, wv)\n",
    "    return v / len(sentence)\n",
    "\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14022197143923812"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = generate_averaged_sentence_vector(\"hello world\", model)\n",
    "vec_b = generate_averaged_sentence_vector(\"dr dr dr\", model)\n",
    "cosine_sim(vec_a, vec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\nworld\ndr\ndr\ndr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14022197143923812"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = generate_sentence_vector_sum(\"hello world\", model)\n",
    "vec_b = generate_sentence_vector_sum(\"dr dr dr\", model)\n",
    "cosine_sim(vec_a, vec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395, 0.8312897985602955], [921, 0.75899388591239825], [392, 0.74481696028392608], [414, 0.73493870519356164], [3923, 0.71813767334821355], [2553, 0.71724840490595287], [1068, 0.7118501522458538], [377, 0.71133853979761985], [362, 0.70684602308440425], [403, 0.70597779368451929], [3059, 0.70409631359083125], [1831, 0.69981714154766639], [623, 0.69804007811543878], [1522, 0.69535971870249058], [376, 0.69523443498906767], [1481, 0.69490161303587739], [3639, 0.6935116673535423], [508, 0.68733776178976491], [1525, 0.68732810554056778], [1642, 0.68721691017456821], [1067, 0.686395468771967], [391, 0.68451861403070724], [371, 0.68310969646242092], [1886, 0.68287109044915961], [1195, 0.6793339125331227]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395, 921, 392, 414, 3923, 2553, 1068, 377, 362, 403, 3059, 1831, 623, 1522, 376, 1481, 3639, 508, 1525, 1642, 1067, 391, 371, 1886, 1195]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "395             Pomegranate, Argan & Grapeseed Body Scrub\n921                                      Candy Body Scrub\n392     Tarocco Orange, Eucalyptus & Sage Deep Cleansi...\n414                        Almond & Aloe Hand & Body Wash\n3923    Bundle Of Joy Set: Newborn 2-in-1 Hair & Body ...\n2553    Lovely Clean & Perfume Body Lotion (Exp. Date ...\n1068                            Lavender Hand & Body Wash\n377     Avocado, Olive & Basil Perfect Pair: Bath & Sh...\n362                Exfoliating Body Scrub for Smooth Skin\n403                        Pear & Pink Magnolia Body Wash\n3059                             Seaweed & Sage Body Wash\n1831                        Elixir Exfoliating Body Scrub\n623                      Creamy Body Scrub - Vanilla Bean\n1522    Vanille & Coco Perfumed Body Cream (New Packag...\n376     Citron, Honey & Coriander Duo: Bath & Shower G...\n1481                        Omnia Coral Gentle Body Scrub\n3639    Strawberry Scrub Fruit Enzyme Polisher - For F...\n508     Nashi Blossom & Pink Grapefruit Skin Softening...\n1525    Amber & Vanilla Perfumed Body Cream (New Packa...\n1642                              Lotus Santal Body Scrub\n1067                             Verbena Hand & Body Wash\n391     Tarocco Orange, Eucalyptus & Sage Skin Silkeni...\n371     Rosewater Perfect Pair: Bath & Shower Gel 250m...\n1886                           Sweet Cilantro Body Lotion\n1195             Lavender Moisturising Hand & Body Lotion\nName: title, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Sweet & Savoury Body Scrub\"\n",
    "\n",
    "\n",
    "def find_top_n_docs(query: str, num_docs, sentences, w2v_model):\n",
    "    \n",
    "    vectors = sentences.map(lambda title: generate_averaged_sentence_vector(title, w2v_model.wv))\n",
    "    query_vector = generate_averaged_sentence_vector(query, w2v_model)\n",
    "    rankings = []\n",
    "    i = 0\n",
    "    for product_vector in vectors:\n",
    "        product_similarity = cosine_sim(query_vector, product_vector)\n",
    "        rankings.append([i, product_similarity])\n",
    "        i += 1\n",
    "        \n",
    "    return_value = sorted(rankings, key=lambda ranking: -ranking[1])\n",
    "    \n",
    "    return return_value[:num_docs]\n",
    "\n",
    "print(find_top_n_docs(query, 25, all_docs['title'], model))\n",
    "\n",
    "result_idx = list(map(lambda item: item[0], find_top_n_docs(query, 25, all_docs['title'], model)))\n",
    "print(result_idx)\n",
    "\n",
    "all_docs.iloc[result_idx][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a custom word2vec model from document titles\n",
    "\n",
    "title_model = gensim.models.Word2Vec(all_docs['title'], min_count=10, workers=4, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape () doesn't match the broadcast shape (100,)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-a7891f79ec83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtitle_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_top_n_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_top_n_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-b3c6d4204fb2>\u001b[0m in \u001b[0;36mfind_top_n_docs\u001b[0;34m(query, num_docs, sentences, w2v_model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_top_n_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerate_averaged_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mquery_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_averaged_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrankings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas\\_libs\\src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas\\_libs\\lib.c:66645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-b3c6d4204fb2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_top_n_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerate_averaged_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mquery_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_averaged_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrankings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-a3cb71d79d09>\u001b[0m in \u001b[0;36mgenerate_averaged_sentence_vector\u001b[0;34m(sentence, wv)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_averaged_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_sentence_vector_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-a3cb71d79d09>\u001b[0m in \u001b[0;36mgenerate_sentence_vector_sum\u001b[0;34m(sentence, wv)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[1;31m#print(w.lower())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape () doesn't match the broadcast shape (100,)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "query = \"Exfoliating Gel\"\n",
    "\n",
    "title_vectors = all_docs[\"title\"]\n",
    "print(find_top_n_docs(query, 25, title_vectors, title_model))\n",
    "\n",
    "result_idx = list(map(lambda item: item[0], find_top_n_docs(query, 25, title_vectors, title_model)))\n",
    "print(result_idx)\n",
    "\n",
    "all_docs.iloc[result_idx][\"title\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}